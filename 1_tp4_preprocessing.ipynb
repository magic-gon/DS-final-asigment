{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.cluster import DBSCAN, KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = \"okcupid_profiles.csv\"\n",
    "data = pd.read_csv(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 31 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          59946 non-null  int64  \n",
      " 1   status       59946 non-null  object \n",
      " 2   sex          59946 non-null  object \n",
      " 3   orientation  59946 non-null  object \n",
      " 4   body_type    54650 non-null  object \n",
      " 5   diet         35551 non-null  object \n",
      " 6   drinks       56961 non-null  object \n",
      " 7   drugs        45866 non-null  object \n",
      " 8   education    53318 non-null  object \n",
      " 9   ethnicity    54266 non-null  object \n",
      " 10  height       59943 non-null  float64\n",
      " 11  income       59946 non-null  int64  \n",
      " 12  job          51748 non-null  object \n",
      " 13  last_online  59946 non-null  object \n",
      " 14  location     59946 non-null  object \n",
      " 15  offspring    24385 non-null  object \n",
      " 16  pets         40025 non-null  object \n",
      " 17  religion     39720 non-null  object \n",
      " 18  sign         48890 non-null  object \n",
      " 19  smokes       54434 non-null  object \n",
      " 20  speaks       59896 non-null  object \n",
      " 21  essay0       54458 non-null  object \n",
      " 22  essay1       52374 non-null  object \n",
      " 23  essay2       50308 non-null  object \n",
      " 24  essay3       48470 non-null  object \n",
      " 25  essay4       49409 non-null  object \n",
      " 26  essay5       49096 non-null  object \n",
      " 27  essay6       46175 non-null  object \n",
      " 28  essay7       47495 non-null  object \n",
      " 29  essay8       40721 non-null  object \n",
      " 30  essay9       47343 non-null  object \n",
      "dtypes: float64(1), int64(2), object(28)\n",
      "memory usage: 14.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables numericas: age, height, income\n",
    "Variables que sacamos por ahora: last_online, todos los essays\n",
    "Variables con nulls="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para las variables categóricas\n",
    "def completar_nodijo(columna):\n",
    "    mask_null = columna.isnull()\n",
    "    columna[mask_null] = \"rather not say\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_cat_a_modificar = ['status', 'sex', 'orientation', 'body_type', 'diet', 'drinks',\n",
    "       'drugs', 'education', 'ethnicity','job', 'location', 'offspring', 'pets', 'religion', 'sign',\n",
    "       'smokes', 'speaks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_921960/1023053484.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  columna[mask_null] = \"rather not say\"\n"
     ]
    }
   ],
   "source": [
    "for i in columnas_cat_a_modificar:\n",
    "    completar_nodijo(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "never             37724\n",
       "rather not say    14080\n",
       "sometimes          7732\n",
       "often               410\n",
       "Name: drugs, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drugs.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columnas que no vamos a utilizar ahora\n",
    "columnas_no_utilizadas = ['essay0', 'essay1', 'essay2', 'essay3', 'essay4',\n",
    "       'essay5', 'essay6', 'essay7', 'essay8', 'essay9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_essays = data[columnas_no_utilizadas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columnas_no_utilizadas, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_921960/3026053226.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.height[data.height.isnull()] = -1\n"
     ]
    }
   ],
   "source": [
    "data.height[data.height.isnull()] = -1\n",
    "#Seria más prolijo hacerlo con un fill na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11504 datos de income valido de 59946\n"
     ]
    }
   ],
   "source": [
    "print(f\"{(data.income != -1).sum()} datos de income valido de {len(data.income)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59946 datos de age valido de 59946\n"
     ]
    }
   ],
   "source": [
    "print(f\"{(data.age != -1).sum()} datos de age valido de {len(data.age)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_last_online = data.pop(\"last_online\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Vamos a separar el dataset en variables categóricas y nominales**\n",
    "Revisar después cuando hagan el laburo en fino de las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat = data[columnas_cat_a_modificar]\n",
    "data_cat_speaks = data_cat.pop(\"speaks\")\n",
    "data_cat_ethnicity = data_cat.pop(\"ethnicity\")\n",
    "data_cat_sign = data_cat.pop(\"sign\")\n",
    "data_cat_religion = data_cat.pop(\"religion\")\n",
    "data_nom = data[[\"age\", \"height\", \"income\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separación por etnia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['white',\n",
       " 'other',\n",
       " 'hispanic / latin',\n",
       " 'rather not say',\n",
       " 'middle eastern',\n",
       " 'native american',\n",
       " 'asian',\n",
       " 'pacific islander',\n",
       " 'indian',\n",
       " 'black']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#obtener un conjunto unico labels por cada etnicity \n",
    "#data[\"ethnicity\"].value_counts()\n",
    "enthinicity_labels = set()\n",
    "\n",
    "#quiero lista unica de elementos x eso uso set()\n",
    "for label in data[\"ethnicity\"]:\n",
    "    etnias = label.split(',')\n",
    "    # para que no se repita el nombre si o si debo remover espacios\n",
    "    for i in etnias:\n",
    "        etnia = i.strip()\n",
    "\n",
    "        enthinicity_labels.add(etnia)\n",
    "    \n",
    "# enthinicity_labels.remove('rather not say') ?    para trabajar c lista\n",
    "enthinicity_labels = list(enthinicity_labels)\n",
    "enthinicity_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener columnas indicadoras por cada valiable categorica \n",
    "\n",
    "total_puntos = len(data[\"ethnicity\"])\n",
    "\n",
    "\n",
    "ethni_cols = {}   \n",
    "\n",
    "for etnia in enthinicity_labels:\n",
    "    ethni_cols[etnia] = [0.0 for i in range(total_puntos)]\n",
    "    \n",
    "for indice in range(total_puntos):\n",
    "    etnias = data[\"ethnicity\"][indice]\n",
    "    for etnia in etnias.split(','):\n",
    "        ethni_cols[etnia.strip()][indice] = 1.0\n",
    "    \n",
    "# add to DF\n",
    "data_cat = pd.merge(data_cat, pd.DataFrame(ethni_cols),how=\"inner\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separación por locación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>south san francisco</td>\n",
       "      <td>california</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oakland</td>\n",
       "      <td>california</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>san francisco</td>\n",
       "      <td>california</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>berkeley</td>\n",
       "      <td>california</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>san francisco</td>\n",
       "      <td>california</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59941</th>\n",
       "      <td>oakland</td>\n",
       "      <td>california</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>san francisco</td>\n",
       "      <td>california</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>south san francisco</td>\n",
       "      <td>california</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59944</th>\n",
       "      <td>san francisco</td>\n",
       "      <td>california</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59945</th>\n",
       "      <td>san francisco</td>\n",
       "      <td>california</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59946 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      city        state country\n",
       "0      south san francisco   california      US\n",
       "1                  oakland   california      US\n",
       "2            san francisco   california      US\n",
       "3                 berkeley   california      US\n",
       "4            san francisco   california      US\n",
       "...                    ...          ...     ...\n",
       "59941              oakland   california      US\n",
       "59942        san francisco   california      US\n",
       "59943  south san francisco   california      US\n",
       "59944        san francisco   california      US\n",
       "59945        san francisco   california      US\n",
       "\n",
       "[59946 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#separando en columnas los elementos separados por comas\n",
    "\n",
    "#   separar por comas, primer elemento columna 1 segundo columna dos. diccionario con dos key, valors van a ser lista 1 y lista 2\n",
    "\n",
    "locs1 = []\n",
    "locs2 = []\n",
    "locscountry = []\n",
    "\n",
    "# crear diccionario clave valor columna lista\n",
    "# \n",
    "\n",
    "for label in data[\"location\"]:\n",
    "    locs = label.split(',')\n",
    "\n",
    "    #valido si tengo una coma inesperada\n",
    "    \n",
    "    if len(locs) > 2:\n",
    "        locscountry.append(locs[2])\n",
    "    else:\n",
    "        locscountry.append(\"US\")\n",
    "\n",
    "    locs1.append(locs[0])\n",
    "    locs2.append(locs[1])\n",
    "location_split = {'city' : locs1 , 'state' : locs2 , 'country' : locscountry}\n",
    "\n",
    "df_location = pd.DataFrame(location_split)\n",
    "df_location\n",
    "\n",
    "# No lo usamos porque estamos usando coordenadas con datos nominales, dejo comentado:\n",
    "# data_cat = pd.merge(data_cat, df_location, how=\"inner\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto no funciona pq es super lento ir uno por uno:\n",
    "# from geopy.geocoders import Nominatim\n",
    "# geolocator = Nominatim(user_agent=\"locator\")\n",
    "\n",
    "# latitude = []\n",
    "# longitude = []\n",
    "\n",
    "# for label in data[\"location\"]:\n",
    "#     loc = geolocator.geocode(label)\n",
    "#     if loc is not None:\n",
    "#         latitude.append(loc.latitude)\n",
    "#         longitude.append(loc.longitude)\n",
    "#     else:\n",
    "#         print(f\"Warning: {label} not recognised\")\n",
    "#         latitude.append(float(\"nan\"))\n",
    "#         longitude.append(float(\"nan\"))\n",
    "\n",
    "# location_coords = {'latitude' : latitude , 'longitude' : longitude}\n",
    "\n",
    "# data_nom += pd.DataFrame(location_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrados 199 en 59946 puntos de dato\n",
      "Lugar no encontrado: green brae, california\n"
     ]
    }
   ],
   "source": [
    "# convertir locacion a coordendas es super lento porque geopy llama a un servicio\n",
    "# para evitar repeticiones primero reducimos con un dict\n",
    "\n",
    "lugares = {}\n",
    "for label in data[\"location\"]:\n",
    "    lugares[label.strip()] = ()\n",
    "\n",
    "puntos = len(data[\"location\"])\n",
    "print(f\"Encontrados {len(lugares)} en {puntos} puntos de dato\")\n",
    "\n",
    "# busca las coordenadas\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"locator\")\n",
    "\n",
    "for lugar, coords in lugares.items():\n",
    "    loc = geolocator.geocode(lugar)\n",
    "    if loc is not None:\n",
    "        lugares[lugar] = (loc.latitude, loc.longitude)\n",
    "    else:\n",
    "        print(f\"Lugar no encontrado: {lugar}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lugares[\"green brae, california\"] = (38.4257453,-121.5963564) # agrego Greenbrae manual\n",
    "\n",
    "latitude = []\n",
    "longitude = []\n",
    "\n",
    "for label in data[\"location\"]:\n",
    "    latitude.append(lugares[label.strip()][0])\n",
    "    longitude.append(lugares[label.strip()][1])\n",
    "\n",
    "location_coords = {'latitude' : latitude , 'longitude' : longitude}\n",
    "\n",
    "data_nom = pd.merge(data_nom, pd.DataFrame(location_coords), how=\"inner\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separación por lenguages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aca removemos la aclaracion de sabiduria pq sino explota el tamanio\n",
    "def clean_language(language):\n",
    "    # eliminamos parentesis que aclara conocimiento, sino el dataset explota\n",
    "    # aca podiramos usar regex pero find es mas simple\n",
    "    par_find = language.find(' (') \n",
    "    if par_find >= 0:\n",
    "        language = language[0:par_find]\n",
    "    return language.strip()\n",
    "\n",
    "\n",
    "#obtener un conjunto unico labels por cada lenguaje \n",
    "language_labels = set()\n",
    "\n",
    "#quiero lista unica de elementos x eso uso set()\n",
    "for label in data[\"speaks\"]:\n",
    "    languages = label.split(',')\n",
    "    # para que no se repita el nombre si o si debo remover espacios\n",
    "    for language in languages:\n",
    "        language_labels.add(clean_language(language))\n",
    "    \n",
    "# language_labels.remove('rather not say') ?    para trabajar c lista\n",
    "\n",
    "\n",
    "# Obtener columnas indicadoras por cada valiable categorica \n",
    "\n",
    "total_puntos = len(data[\"speaks\"])\n",
    "\n",
    "\n",
    "language_cols = {}   \n",
    "\n",
    "for language in language_labels:\n",
    "    language_cols[language] = [0.0 for i in range(total_puntos)]\n",
    "    \n",
    "for indice in range(total_puntos):\n",
    "    languages = data[\"speaks\"][indice]\n",
    "    for language in languages.split(','):\n",
    "        language_cols[clean_language(language)][indice] = 1.0\n",
    "    \n",
    "# add to DF\n",
    "data_lan = pd.DataFrame(language_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'afrikaans',\n",
       " 'albanian',\n",
       " 'ancient greek',\n",
       " 'arabic',\n",
       " 'armenian',\n",
       " 'basque',\n",
       " 'belarusan',\n",
       " 'bengali',\n",
       " 'breton',\n",
       " 'bulgarian',\n",
       " 'c++',\n",
       " 'catalan',\n",
       " 'cebuano',\n",
       " 'chechen',\n",
       " 'chinese',\n",
       " 'croatian',\n",
       " 'czech',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'esperanto',\n",
       " 'estonian',\n",
       " 'farsi',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'frisian',\n",
       " 'georgian',\n",
       " 'german',\n",
       " 'greek',\n",
       " 'gujarati',\n",
       " 'hawaiian',\n",
       " 'hebrew',\n",
       " 'hindi',\n",
       " 'hungarian',\n",
       " 'icelandic',\n",
       " 'ilongo',\n",
       " 'indonesian',\n",
       " 'irish',\n",
       " 'italian',\n",
       " 'japanese',\n",
       " 'khmer',\n",
       " 'korean',\n",
       " 'latin',\n",
       " 'latvian',\n",
       " 'lisp',\n",
       " 'lithuanian',\n",
       " 'malay',\n",
       " 'maori',\n",
       " 'mongolian',\n",
       " 'norwegian',\n",
       " 'occitan',\n",
       " 'other',\n",
       " 'persian',\n",
       " 'polish',\n",
       " 'portuguese',\n",
       " 'rather not say',\n",
       " 'romanian',\n",
       " 'rotuman',\n",
       " 'russian',\n",
       " 'sanskrit',\n",
       " 'sardinian',\n",
       " 'serbian',\n",
       " 'sign language',\n",
       " 'slovak',\n",
       " 'slovenian',\n",
       " 'spanish',\n",
       " 'swahili',\n",
       " 'swedish',\n",
       " 'tagalog',\n",
       " 'tamil',\n",
       " 'thai',\n",
       " 'tibetan',\n",
       " 'turkish',\n",
       " 'ukrainian',\n",
       " 'urdu',\n",
       " 'vietnamese',\n",
       " 'welsh',\n",
       " 'yiddish'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separación por signo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separando en columnas. el primer elemento es el signo, y el segundo, cuanto le importa\n",
    "\n",
    "sign = []\n",
    "sign_matters = []\n",
    "\n",
    "# crear diccionario clave valor columna lista\n",
    "\n",
    "\n",
    "for label in data[\"sign\"]:\n",
    "    signs = label.split(maxsplit=1)\n",
    "\n",
    "    sign.append(signs[0])\n",
    "    if len(signs)>1:\n",
    "        sign_matters.append(signs[1])\n",
    "    else:\n",
    "        sign_matters.append('rather not say')  \n",
    "    \n",
    "df_sign = pd.DataFrame({'sign' : sign , 'sign_matters' : sign_matters})\n",
    "data_cat = pd.merge(data_cat, df_sign, how=\"inner\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separación por pets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separando en columnas. el primer elemento es el signo, y el segundo, cuanto le importa\n",
    "\n",
    "dogs = []\n",
    "cats = []\n",
    "\n",
    "# crear diccionario clave valor columna lista\n",
    "\n",
    "\n",
    "for label in data[\"pets\"]:\n",
    "    \n",
    "    # Modifico la columna para que tenga toda el mismo formato\n",
    "    # Cambio las que no tenían dato\n",
    "    if label == 'rather not say':\n",
    "        label = 'no_opinion dogs and no_opinion cats'\n",
    "    # Cambio las que tienen opinión solo de una mascota\n",
    "    if label.find('and') == -1:\n",
    "        if label.find('cats') == -1:\n",
    "            label = label + \" and no_opinion cats\"\n",
    "        else:\n",
    "            label = \"no_opinion dogs and \" + label\n",
    "    \n",
    "    pets = label.split('and')\n",
    "\n",
    "    dogs.append(pets[0])\n",
    "    cats.append(pets[1])\n",
    "\n",
    "    \n",
    "df_pets = pd.DataFrame({'dogs' : dogs , 'cats' : cats})\n",
    "data_cat = pd.merge(data_cat, df_pets, how=\"inner\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframes\n",
    "\n",
    "data_nom.to_csv(\"data_nom.csv\", index = False)\n",
    "data_cat.to_csv(\"data_cat.csv\", index = False)\n",
    "data_lan.to_csv(\"data_lan.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1cf87801752c1f8903463c6bebb73821df73cbbd6d99a7a178eb46b3f56ec669"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "96bac1fc5bed2d9ec687dc0496e575925268755460a668eb167ac3c883c16da8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
